{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3 \n",
    "import botocore\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseURL = 'baseURL'\n",
    "class S3Bucket:\n",
    "    \"\"\"\n",
    "    Connection with AWS S3Bucket\n",
    "    needs boto3 and botocore to make a connection and download\n",
    "    \"\"\"\n",
    "    def __init__(self, access_key=\"\", bucket=\"\", secret_key=\"\"):\n",
    "        \"\"\"\n",
    "        access_key (string) = access_key for s3bucket\n",
    "        bucket (string) = the bucket from which download will be requested\n",
    "        secret_key (string) = secret_key for s3bucket\n",
    "    \n",
    "        \"\"\"\n",
    "        self.name = 's3'\n",
    "        self.bucket = bucket\n",
    "        self.client = boto3.client(self.name,\n",
    "                              aws_access_key_id=access_key,\n",
    "                              aws_secret_access_key=secret_key)\n",
    "\n",
    "    \n",
    "    def downloadFile(self, file_key, destination_path):\n",
    "        \"\"\"\n",
    "        downloads the file from file_key (string) and saves it to path destination_path(string)\n",
    "        the destination path must exists for successful download\n",
    "        \"\"\"\n",
    "        self.client.download_file(self.bucket, \n",
    "                             file_key, \n",
    "                             destination_path)\n",
    "\n",
    "class Server:\n",
    "    \"\"\"\n",
    "    Contains all necessery constants to make a AYT call to backend\n",
    "    Makes AYT call to backend and sets server parameters ready for fetching either from s3 or from backend\n",
    "    Creates and assigns as a property a instance of S3Bucket after receiving config data from AYT\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        - authorization(string): authorization for the request\n",
    "        - contentType: type of the requested content\n",
    "        - agentUser: name of the client\n",
    "        - endPoint: url of Backend API\n",
    "        - s3bucket: instance of S3Bucket which enables downloading of files from S3\n",
    "        \"\"\"\n",
    "        self.authorization = 'Basic'\n",
    "        self.contentType = 'application/json'\n",
    "        self.agentUser = \"PythonML\"\n",
    "        self.endPoint = \"\"\n",
    "        self.s3bucket = S3Bucket()\n",
    "    \n",
    "    def makeAYT(self):\n",
    "        \"\"\"\n",
    "        - makes AYT call to backend \n",
    "        - parses the response. \n",
    "        - sets backend endPoint\n",
    "        - sets S3Bucket\n",
    "        \"\"\"\n",
    "        headers = self.createHeader()\n",
    "        \n",
    "        data = '{\"operation\":\"AYT\",\n",
    "                    \"version\":{\"protocol\":\n",
    "                                   {\"domain_model\":\"5\",\n",
    "                                    \"API\":\"4\"},\n",
    "                               \"client\":\"PythonML\"}}'\n",
    "        \n",
    "        response = requests.post(baseURL, headers=headers, data=data)\n",
    "        js = response.json()\n",
    "        \n",
    "        for server in js['servers']:\n",
    "            if server['name'] == 'json':\n",
    "                self.endPoint = server['prefix']\n",
    "            elif server['name'] == 's3':\n",
    "                self.s3bucket = S3Bucket(access_key=server['access_key'],\n",
    "                                         secret_key=server['secret_key'],\n",
    "                                         bucket=server['bucket'])\n",
    "    def createHeader(self):\n",
    "        \"\"\"\n",
    "        return request header \n",
    "        \"\"\"\n",
    "        headers = {'Authorization': self.authorization,\n",
    "                   'Content-Type': self.contentType,\n",
    "                   'User-Agent': self.agentUser}\n",
    "        return headers\n",
    "    \n",
    "    def downloadFileFromS3Bucket(self, file_key, destination_file):\n",
    "        \"\"\"\n",
    "        downloads the file from file_key (string) and saves it to path destination_path(string)\n",
    "        the destination path must exists for successful download\n",
    "        \"\"\"\n",
    "        self.s3bucket.downloadFile(file_key, destination_file)\n",
    "        \n",
    "    \n",
    "    def getJSONFromServer(self,record_type, operation=\"read\", maxResults=1000, sortKey=\"created\", \n",
    "                          sortDirection=\"descending\", depth=1, \n",
    "                          filterValue='2040-01-01', filter_operator='<', filterKey='created'):\n",
    "        \"\"\"\n",
    "        generic method for fetching any record type from the backend\n",
    "        - record_type (str) - type to be fetched\n",
    "        - operation (str) - which operation to be performed (default: \"read\")\n",
    "        - maxResults (str) - maximum number of the items to be returned (default: 1000)\n",
    "        - sortKey (str) - the key to be used for sorting  (default: \"created\")\n",
    "        - sortDirection (str) - ascedning/descending (default: descending)\n",
    "        - filterKey (str) - the key to be used for filtering (default: \"created\")\n",
    "        - filterValue (str) - the value to be used for filtering (default: \"2040-01-01\")\n",
    "        - filter_operator (str) - the operator to be applied to filterKey and filterValue (default: \"<\")\n",
    "        \n",
    "        returns serialized json from the response\n",
    "        \"\"\"\n",
    "        data = json.dumps({\"depth\":depth,\n",
    "                \"type\":record_type,\n",
    "                \"paging\":\n",
    "                    {\"maxResults\":maxResults,\n",
    "                     \"sort\":\n",
    "                         {\"key\":sortKey,\n",
    "                          \"direction\":sortDirection}},\n",
    "                \"operation\":operation, \n",
    "                \"filter\":[\n",
    "                    {\"value\":filterValue,\n",
    "                     \"operator\":filter_operator,\n",
    "                     \"key\":filterKey}]})\n",
    "        response = requests.post(self.endPoint, headers=self.createHeader(), data=data)\n",
    "        js = response.json()\n",
    "        return js\n",
    "    \n",
    "    def getAllScenes(self):\n",
    "        \"\"\"\n",
    "        returns all scenes meta data from the backend\n",
    "        \"\"\"\n",
    "        js = self.getJSONFromServer(\"scene\", filterValue=str(datetime.datetime.now()))                \n",
    "        js_all = [js]\n",
    "        while len(js)>0:\n",
    "            js_all.append(js)\n",
    "            last = js[-1]\n",
    "            last_date = last['meta']['created']\n",
    "            js = self.getJSONFromServer(\"scene\", filterValue=str(last_date))  \n",
    "        jsallflat = [x for sub in js_all for x in sub]\n",
    "        return jsallflat\n",
    "    \n",
    "    \n",
    "    def getAllRealEstate(self):\n",
    "        \"\"\"\n",
    "        returns all Real Esate Properties meta data from the backend\n",
    "        \"\"\"\n",
    "        js = self.getJSONFromServer(\"real_estate_property\", depth=2, filterValue=str(datetime.datetime.now()))                \n",
    "        js_all = [js]\n",
    "        while len(js)>0:\n",
    "            js_all.append(js)\n",
    "            last = js[-1]\n",
    "            last_date = last['meta']['created']\n",
    "            js = self.getJSONFromServer(\"real_estate_property\", depth=2, filterValue=str(last_date))\n",
    "        jsallflat = [x for sub in js_all for x in sub]\n",
    "        return jsallflat\n",
    "    \n",
    "class DataParser:\n",
    "    def getUrlForZipForScenes(self,js):\n",
    "        \"\"\"\n",
    "        js (list) - list of dictionaries of scenes\n",
    "        returns list of urls of the scenes provided as list of dict\n",
    "        \n",
    "        \"\"\"\n",
    "        urls = []\n",
    "        for item in js:\n",
    "            urls.append(item['data']['url'])\n",
    "        return urls\n",
    "    \n",
    "class FileManager:\n",
    "    def get_only_xml_from_zip(self, path_to_zip_file, destination_path ):\n",
    "        \"\"\"\n",
    "        path_to_zip_file - path to the zip file\n",
    "        destination_path - path for unzip folder\n",
    "        unzips the file from the path_to_zip_file to destination_path and gets only the scene xml file in\n",
    "        scenexmls folder\n",
    "        \"\"\"\n",
    "        zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
    "        zip_ref.extractall(destination_path)\n",
    "        zip_ref.close()\n",
    "        os.remove(path_to_zip_file)\n",
    "        os.remove(destination_path + \"/original.jpg\")\n",
    "        os.rename(destination_path + \"/project.xml\", \"scenexmls/\"+key+\".xml\")\n",
    "    \n",
    "class SceneParser:\n",
    "    def parseAllScenesXML(self):\n",
    "        \"\"\"\n",
    "        Takes all xml files from the folder scenexmls and parses them\n",
    "        return dataframe which contains as rows all products in all scenes and as columns:\n",
    "        product_id, x, y, z, rotation and scene_id\n",
    "        \"\"\"\n",
    "        dfs = []\n",
    "        files = []\n",
    "        for r, d, f in os.walk(\"scenexmls/\"):\n",
    "            for file in f:\n",
    "                files.append(os.path.join(r, file))\n",
    "        for file in files:\n",
    "            if '.xml' in file:\n",
    "                xmlfile = ET.parse(file)\n",
    "                root = xmlfile.getroot()\n",
    "                ready4df=[]\n",
    "                for i in root.findall('object'):\n",
    "                    ready4df.append(i.attrib)\n",
    "                df = pd.DataFrame(ready4df)\n",
    "                key = file.split(\"/\")[1].split(\".\")[0]\n",
    "                df['scene_id'] = key\n",
    "                dfs.append(df)\n",
    "        dfscenes = pd.concat(dfs).reset_index().drop('index', axis=1)\n",
    "        return dfscenes\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createScenesBasetable()\n",
    "    \"\"\"\n",
    "    Integrated flow fucntion\n",
    "    returns scenes basetable with position and rotatio of each product in the scenes\n",
    "    \"\"\"\n",
    "    #1. creates a server\n",
    "    server = Server()\n",
    "    #2. Makes a AYT call to obtain S3 bucket connection enablers and end point for meta data\n",
    "    server.makeAYT()\n",
    "    #3. Retrieves all scenes \n",
    "    allscenes = server.getAllScenes()\n",
    "    #4. Get urls to download the files from S3Bucket\n",
    "    urls = DataParser().getUrlForZipForScenes(jsallflat)\n",
    "    #5. Downlaod all scene zip files and extract the xml file\n",
    "    for url in set(urls):\n",
    "        key = url.split(\"/\")[0]\n",
    "        server.downloadFileFromS3Bucket(url, \"scenes/\" + key + \".zip\")\n",
    "        FileManager().get_only_xml_from_zip(\"scenes/\" + key + \".zip\", \"unzipped/\" + key )\n",
    "    #6 create dataframe from the scene xml\n",
    "    dfscenes = SceneParser().parseAllScenesXML()\n",
    "    return dfscenes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>rotation</th>\n",
       "      <th>scene_zip_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d29cb731-1a03-4822-9f75-d523fabec631</td>\n",
       "      <td>-1.7365966797e+01</td>\n",
       "      <td>be9fa381-e026-41a4-9d98-5b034ffd8237</td>\n",
       "      <td>1.0482574701e+00</td>\n",
       "      <td>-7.9321825504e-01</td>\n",
       "      <td>-3.4925968647e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cb855f91-879f-42e7-9793-eafda352b139</td>\n",
       "      <td>8.5528976440e+01</td>\n",
       "      <td>be9fa381-e026-41a4-9d98-5b034ffd8237</td>\n",
       "      <td>1.1975824833e+00</td>\n",
       "      <td>-9.0163052082e-01</td>\n",
       "      <td>-1.7694252729e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee543266-0e24-4029-be6e-f92a775cadcb</td>\n",
       "      <td>-3.6798454285e+01</td>\n",
       "      <td>be9fa381-e026-41a4-9d98-5b034ffd8237</td>\n",
       "      <td>1.2431117296e+00</td>\n",
       "      <td>-7.9322725534e-01</td>\n",
       "      <td>-3.2318880558e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cb855f91-879f-42e7-9793-eafda352b139</td>\n",
       "      <td>4.3247184753e+00</td>\n",
       "      <td>be9fa381-e026-41a4-9d98-5b034ffd8237</td>\n",
       "      <td>-3.3459293842e-01</td>\n",
       "      <td>-8.7053245306e-01</td>\n",
       "      <td>-2.8342216015e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c7e7c896-c270-49e8-97a7-bbb01ca87c2c</td>\n",
       "      <td>-4.2695732117e+01</td>\n",
       "      <td>be9fa381-e026-41a4-9d98-5b034ffd8237</td>\n",
       "      <td>1.9278702736e+00</td>\n",
       "      <td>-9.0137094259e-01</td>\n",
       "      <td>-2.7674129009e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              productId           rotation  \\\n",
       "0  d29cb731-1a03-4822-9f75-d523fabec631  -1.7365966797e+01   \n",
       "1  cb855f91-879f-42e7-9793-eafda352b139   8.5528976440e+01   \n",
       "2  ee543266-0e24-4029-be6e-f92a775cadcb  -3.6798454285e+01   \n",
       "3  cb855f91-879f-42e7-9793-eafda352b139   4.3247184753e+00   \n",
       "4  c7e7c896-c270-49e8-97a7-bbb01ca87c2c  -4.2695732117e+01   \n",
       "\n",
       "                           scene_zip_id                  x                  y  \\\n",
       "0  be9fa381-e026-41a4-9d98-5b034ffd8237   1.0482574701e+00  -7.9321825504e-01   \n",
       "1  be9fa381-e026-41a4-9d98-5b034ffd8237   1.1975824833e+00  -9.0163052082e-01   \n",
       "2  be9fa381-e026-41a4-9d98-5b034ffd8237   1.2431117296e+00  -7.9322725534e-01   \n",
       "3  be9fa381-e026-41a4-9d98-5b034ffd8237  -3.3459293842e-01  -8.7053245306e-01   \n",
       "4  be9fa381-e026-41a4-9d98-5b034ffd8237   1.9278702736e+00  -9.0137094259e-01   \n",
       "\n",
       "                   z  \n",
       "0  -3.4925968647e+00  \n",
       "1  -1.7694252729e+00  \n",
       "2  -3.2318880558e+00  \n",
       "3  -2.8342216015e+00  \n",
       "4  -2.7674129009e+00  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = createScenesBasetable()\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_estate = server.getAllRealEstate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
